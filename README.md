# Eratani Data Engineer Technical Assessment

Pipeline data end-to-end untuk memproses data produksi pertanian menggunakan **Apache Airflow**, **dbt**, dan **PostgreSQL**.

Project ini dibuat sebagai bagian dari **Eratani Data Engineer Technical Assessment**.

---

## ğŸ”§ Tech Stack

- Apache Airflow â€” Orkestrasi pipeline
- dbt â€” Transformasi & data modeling
- PostgreSQL â€” Data warehouse
- Docker & Docker Compose â€” Containerization
- Python â€” Data ingestion

---

## ğŸ“‚ Project Structure

```text
eratani_etl/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ eratani_agriculture_dag.py
â”œâ”€â”€ dbt_projects/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ staging/
â”‚       â”‚   â””â”€â”€ stg_agriculture.sql
â”‚       â””â”€â”€ marts/
â”‚           â”œâ”€â”€ fact_farm_production.sql
â”‚           â”œâ”€â”€ agriculture_metrics.sql
â”‚           â””â”€â”€ agriculture_metrics_daily.sql
â”œâ”€â”€ data/
â”‚   â””â”€â”€ agriculture_dataset.csv
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
# Alur Pipeline Data
1. Ingestion (Airflow)

- File agriculture_dataset.csv dibaca menggunakan Python

- Data dimasukkan ke tabel staging_agriculture di PostgreSQL

- Proses ingestion bersifat idempotent (TRUNCATE sebelum insert)

- Jumlah baris data dicatat di log Airflow

2. Transformasi (dbt)

- stg_agriculture
- Membersihkan data (casting tipe data, trimming string, filter null)

- fact_farm_production
- Tabel fakta berisi data pertanian yang sudah bersih dan terstruktur

- agriculture_metrics_daily
- Tabel metrics yang berisi insight siap pakai

3. Orcrestration (penjadwalan)

- Airflow menjalankan ingestion dan dbt secara berurutan

- DAG dijalankan setiap hari pukul 06:00 UTC

# Cara Menjalankan Project
1. Jalankan Docker Compose
```
docker compose up -d

```
2. Akses Airflow UI
```
URL: http://localhost:8080

Username: admin

Password: admin123
```
3. Jalankan DAG

Aktifkan dan jalankan DAG:
```
eratani_agriculture_etl
```
Pipeline akan:

Load CSV ke PostgreSQL

Menjalankan seluruh model dbt

Menghasilkan tabel metrics

# ğŸ“ Notes

Project ini dijalankan sepenuhnya secara lokal menggunakan Docker

Struktur pipeline mengikuti best practice data engineering:

Orkestrasi terpisah dari transformasi

Transformasi terpusat di dbt

Metrics siap pakai untuk analisis atau BI tools
